{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import time\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import numpy as np  \n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras import layers, activations\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,ZeroPadding2D,BatchNormalization,Activation,Add,Dot,AveragePooling2D,Lambda\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_name):\n",
    "    im=cv2.imread(image_name)\n",
    "    im=cv2.resize(im, (224, 224))\n",
    "    return im\n",
    "\n",
    "#数据扩充\n",
    "def img_Rotation(img,angel):\n",
    "    if(0 == angel):\n",
    "        dst = img\n",
    "    else:\n",
    "        rows,cols=img.shape[:2]\n",
    "        #angel度旋转\n",
    "        M=cv2.getRotationMatrix2D((cols/2,rows/2),angel,1)\n",
    "        dst=cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'AID'\n",
    "Extension='.jpg'\n",
    "\n",
    "base_path='./Dataset/' + dataset\n",
    "\n",
    "All_Labels = os.listdir(os.path.join(base_path, 'Train'))\n",
    "num_classes = len(All_Labels)\n",
    "images_Train = []\n",
    "labels_Train = []\n",
    "images_Val = []\n",
    "labels_Val = []\n",
    "\n",
    "for i in range(0, num_classes):\n",
    "    file_dir = os.path.join(base_path, 'Train', All_Labels[i])\n",
    "    file_names = os.listdir(file_dir)\n",
    "    for file_name in file_names:\n",
    "        if(file_name.endswith(Extension)):\n",
    "            finalFileName = os.path.join(file_dir, file_name)\n",
    "            Label = np.linspace(0, 0, num_classes, dtype='int32')\n",
    "            Label[i] = 1\n",
    "            original_img = read_image(finalFileName)\n",
    "            flipped_img = cv2.flip(original_img, 0)\n",
    "            \n",
    "            for j in [0, 45, 90, 135, 180, 225, 270, 315]: \n",
    "                images_Train.append(img_Rotation(original_img, j))\n",
    "                labels_Train.append(Label)               \n",
    "                images_Train.append(img_Rotation(flipped_img, j))\n",
    "                labels_Train.append(Label)               \n",
    "                \n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"Get %d Train Images\" %(len(images_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \" np.array\")\n",
    "X_Train = np.array(images_Train, dtype='float32')\n",
    "Y_Train = np.array(labels_Train)\n",
    "del images_Train\n",
    "gc.collect()\n",
    "\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \" preprocess\")\n",
    "X_Train = preprocess_input(X_Train)\n",
    "\n",
    "gc.collect()\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \" Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelName = \"Gabor-CA-ResNet50\"\n",
    "batch_size = 16\n",
    "epochs = 50  \n",
    "num_classes = Y_Train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def Gabor(shape, dtype=None):    \n",
    "    ksize = (7, 7)\n",
    "    # 核尺寸\n",
    "    #sigmas = [1] # [2, 4]\n",
    "    # 角度\n",
    "    #thetas = np.linspace(0, 2*np.pi, 8, endpoint=False) # np.linspace(0, np.pi, 4, endpoint=False)\n",
    "    # 波长(间隔)\n",
    "    #lambdas = np.linspace(2, 3, 6) # [8, 16, 32, 64]\n",
    "    # 高度(越小，核函数图像会越高)\n",
    "    #gammas = [1] # np.linspace(1, 0, 2, endpoint=False)\n",
    "    # 中轴\n",
    "    #psis = [0, 2*np.pi]\n",
    "    \n",
    "    gabors = []\n",
    "    \n",
    "    for i in range(0,int(64/4)):    \n",
    "#     size, sigma, theta, lambda, gamma aspect ratio                 \n",
    "        gf = cv2.getGaborKernel(ksize=ksize, sigma=1, theta=0, lambd=2, gamma=1, psi=0, ktype=cv2.CV_32F)\n",
    "        gabors.append(gf)             \n",
    "        gf = cv2.getGaborKernel(ksize=ksize, sigma=1, theta=np.pi/2, lambd=2, gamma=1, psi=0, ktype=cv2.CV_32F)\n",
    "        gabors.append(gf)             \n",
    "        gf = cv2.getGaborKernel(ksize=ksize, sigma=1, theta=np.pi/4, lambd=2, gamma=1, psi=0, ktype=cv2.CV_32F)\n",
    "        gabors.append(gf)             \n",
    "        gf = cv2.getGaborKernel(ksize=ksize, sigma=1, theta=np.pi/4*3, lambd=2, gamma=1, psi=0, ktype=cv2.CV_32F)\n",
    "        gabors.append(gf)\n",
    "    stacked_list = np.array([gabors])\n",
    "    stacked_list = np.einsum('hijk->jkhi', stacked_list)\n",
    "    \n",
    "    b = K.constant(stacked_list, dtype='float32')\n",
    "    F_0 = Lambda(lambda x: K.cast(x, dtype='float32'))(b)\n",
    "    return F_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_params = {\n",
    "    'epsilon': 9.999999747378752e-06,\n",
    "}\n",
    "\n",
    "def residual_block(input_tensor, filters, reduction=16, strides=1, **kwargs):\n",
    "    x = input_tensor\n",
    "    residual = input_tensor\n",
    "\n",
    "    # bottleneck\n",
    "    x = Conv2D(filters // 4, (1, 1), kernel_initializer='he_uniform', strides=strides, use_bias=False)(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(1)(x)\n",
    "    x = Conv2D(filters // 4, (3, 3), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), kernel_initializer='he_uniform', use_bias=False)(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "\n",
    "    #  if number of filters or spatial dimensions changed\n",
    "    #  make same manipulations with residual connection\n",
    "    x_channels = K.int_shape(x)[-1]\n",
    "    r_channels = K.int_shape(residual)[-1]\n",
    "\n",
    "    if strides != 1 or x_channels != r_channels:\n",
    "\n",
    "        residual = Conv2D(x_channels, (1, 1), strides=strides, kernel_initializer='he_uniform', use_bias=False)(residual)\n",
    "        residual = BatchNormalization(**bn_params)(residual)\n",
    "\n",
    "    # apply attention module\n",
    "    x = ChannelSE(x, reduction=reduction)\n",
    "\n",
    "    # add residual connection\n",
    "    x = Add()([x, residual])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def ChannelSE(input_tensor, reduction=16):  \n",
    "    channels = K.int_shape(input_tensor)[-1]\n",
    "    x = Lambda(lambda a: K.mean(a, axis=[1, 2], keepdims=True))(input_tensor)\n",
    "    x = Conv2D(channels // reduction, (1, 1), kernel_initializer='he_uniform', activation=activations.relu)(x)\n",
    "    x = Conv2D(channels, (1, 1), kernel_initializer='he_uniform', activation=activations.hard_sigmoid)(x)\n",
    "    return layers.Multiply()([input_tensor,x])    #给通道加权重\n",
    "    \n",
    "from keras.optimizers import SGD  \n",
    "def GaborCAResNet(shape):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        \n",
    "    img_input = Input(shape=shape)  \n",
    "\n",
    "    x = ZeroPadding2D(3)(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=2, use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(3)(x)\n",
    "    x = Conv2D(64, (7, 7), strides=1, use_bias=False, kernel_initializer=Gabor, name='Gabor')(x)\n",
    "    x = BatchNormalization(**bn_params, name='Gabor-Batch')(x)\n",
    "    x = Activation('relu', name='Gabor-relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(1)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2)(x)\n",
    "    \n",
    "    # body of resnet\n",
    "    filters = 128\n",
    "    for i, stage in enumerate([3, 4, 6, 3]):\n",
    "\n",
    "        # increase number of filters with each stage\n",
    "        filters *= 2\n",
    "        reduction = 16\n",
    "\n",
    "        for j in range(stage):\n",
    "            # decrease spatial dimensions for each stage (except first, because we have maxpool before)\n",
    "            if i == 0 and j == 0:\n",
    "                x = residual_block(x, filters, reduction=reduction, strides=1, is_first=True)\n",
    "            elif i != 0 and j == 0:\n",
    "                x = residual_block(x, filters, reduction=reduction, strides=2)\n",
    "            else:\n",
    "                x = residual_block(x, filters, reduction=reduction, strides=1)\n",
    "    \n",
    "   \n",
    "\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='output')(x)  \n",
    "\n",
    "    model = Model(inputs=img_input,outputs=x, name=ModelName)  \n",
    "    sgd = SGD(decay=0.0001,momentum=0.9)  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = GaborCAResNet(X_Train.shape[1:])\n",
    "model.load_weights('./models/SeResNet50.h5', by_name=True)\n",
    "model.summary()\n",
    "model.layers[6].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "save_folder = 'models/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + dataset\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# serialize model to JSON\n",
    "#import pickle\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_folder, ModelName + \".json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save(os.path.join(save_folder, ModelName + \".h5\"))\n",
    "print(\"Saved Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "Extension='.jpg'\n",
    "All_Labels = os.listdir(os.path.join(base_path, 'Test'))\n",
    "images = []\n",
    "labels = []\n",
    "outputFileName = []\n",
    "\n",
    "save_folder = 'FeatureMap/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + ModelName + '/' + dataset  +'/'\n",
    "\n",
    "for i in range(0, num_classes):\n",
    "    file_dir = os.path.join(base_path, 'Test', All_Labels[i])\n",
    "    file_names = os.listdir(file_dir)\n",
    "    for file_name in file_names:\n",
    "        if(file_name.endswith(Extension)):\n",
    "            finalFileName = os.path.join(file_dir, file_name)\n",
    "            Label = np.linspace(0, 0, num_classes, dtype='int32')\n",
    "            Label[i] = 1    \n",
    "            images.append(read_image(finalFileName))\n",
    "            labels.append(Label)\n",
    "            outputFileName.append(os.path.join(save_folder, All_Labels[i], file_name).replace(Extension, \".txt\"))\n",
    "\n",
    "print(\"Get %d Test Images\" %(len(images)))\n",
    "output = np.array(images, dtype=\"float32\")\n",
    "output = preprocess_input(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from keras.models import Model  \n",
    "OutPutLayer = Model(inputs=model.input, outputs=model.get_layer('avg_pool').output)\n",
    "print(\"Saved FeatureMap to disk...\")\n",
    "OutputFeatures=[]\n",
    "for i in range(0, len(output)):\n",
    "    p = OutPutLayer.predict(output[i : i + 1])\n",
    "    out=np.reshape(p,p.shape[1])\n",
    "    OutputFeatures.append(out)\n",
    "    print(\"\\r当前输出：%d\" %(i + 1), end= \" \")\n",
    "\n",
    "OutputFeatures = np.array(OutputFeatures, dtype=\"float\") \n",
    "save_folder = 'FeatureMap/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + ModelName + '/' + dataset  +'/'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "np.savetxt(os.path.join(save_folder, dataset + '-Test-2048D.txt'), OutputFeatures)\n",
    "print(\"\\n保存完成！\")\n",
    "print(OutputFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from keras.models import Model  \n",
    "OutPutLayer = Model(inputs=model.input, outputs=model.get_layer('avg_pool').output)\n",
    "print(\"Saved FeatureMap to disk...\")\n",
    "OutputFeatures=[]\n",
    "for i in range(0, len(X_Train)):\n",
    "    p = OutPutLayer.predict(X_Train[i : i + 1])\n",
    "    out=np.reshape(p,p.shape[1])\n",
    "    OutputFeatures.append(out)\n",
    "    print(\"\\r当前输出：%d\" %(i + 1), end= \" \")\n",
    "\n",
    "OutputFeatures = np.array(OutputFeatures, dtype=\"float\") \n",
    "save_folder = 'FeatureMap/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + ModelName + '/' + dataset  +'/'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "np.savetxt(os.path.join(save_folder, dataset + '-Train-2048D.txt'), OutputFeatures)\n",
    "print(\"\\n保存完成！\")\n",
    "print(OutputFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
