{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Dense,Dropout,Lambda,Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'AID'\n",
    "base_path='./FeatureMap/2020-11-28/Gabor-CA-ResNet50/' + dataset\n",
    "ModelName = \"Gabor-CA-ResNet50DNN\"\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "DNNlayers = [ 64, 8 ]\n",
    "\n",
    "X_Train = np.loadtxt(base_path + \"/\" + dataset + \"-Train-2048D.txt\");\n",
    "Y_Train = np.load('./Dataset/' + dataset + \"/Y_Train.npy\");\n",
    "\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \" Get %d Train Images\" %(len(X_Train)))  \n",
    "num_classes = Y_Train.shape[1]\n",
    "steps = int(X_Train.shape[1] / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD  \n",
    "def DNN(shape):\n",
    "    img_input = Input(shape=shape)  \n",
    "    x = img_input\n",
    "    x1 = Lambda(lambda x: x[:,0:steps])(x)\n",
    "    x2 = Lambda(lambda x: x[:,steps:steps*2])(x)\n",
    "    x3 = Lambda(lambda x: x[:,steps*2:steps*3])(x)\n",
    "    x4 = Lambda(lambda x: x[:,steps*3:steps*4])(x)\n",
    "    x5 = Lambda(lambda x: x[:,steps*4:steps*5])(x)\n",
    "    x6 = Lambda(lambda x: x[:,steps*5:steps*6])(x)\n",
    "    x7 = Lambda(lambda x: x[:,steps*6:steps*7])(x)\n",
    "    x8 = Lambda(lambda x: x[:,steps*7:])(x)\n",
    "    for n in DNNlayers:\n",
    "        x1 = Dense(n, activation='relu', name='fc%d-1' %n)(x1)  \n",
    "        x1 = Dropout(0.5)(x1)\n",
    "    for n in DNNlayers:\n",
    "        x2 = Dense(n, activation='relu', name='fc%d-2' %n)(x2)  \n",
    "        x2 = Dropout(0.5)(x2)\n",
    "    for n in DNNlayers:\n",
    "        x3 = Dense(n, activation='relu', name='fc%d-3' %n)(x3)  \n",
    "        x3 = Dropout(0.5)(x3)\n",
    "    for n in DNNlayers:\n",
    "        x4 = Dense(n, activation='relu', name='fc%d-4' %n)(x4)  \n",
    "        x4 = Dropout(0.5)(x4)\n",
    "    for n in DNNlayers:\n",
    "        x5 = Dense(n, activation='relu', name='fc%d-5' %n)(x5)  \n",
    "        x5 = Dropout(0.5)(x5)\n",
    "    for n in DNNlayers:\n",
    "        x6 = Dense(n, activation='relu', name='fc%d-6' %n)(x6)  \n",
    "        x6 = Dropout(0.5)(x6)\n",
    "    for n in DNNlayers:\n",
    "        x7 = Dense(n, activation='relu', name='fc%d-7' %n)(x7)  \n",
    "        x7 = Dropout(0.5)(x7)\n",
    "    for n in DNNlayers:\n",
    "        x8 = Dense(n, activation='relu', name='fc%d-8' %n)(x8)  \n",
    "        x8 = Dropout(0.5)(x8)\n",
    "    x = Concatenate(axis=1, name='outputFeature')([x1, x2, x3, x4, x5, x6, x7, x8])\n",
    "    x = Dense(num_classes, activation='softmax', name='output')(x)  \n",
    "    \n",
    "    model = Model(inputs=img_input,outputs=x, name=ModelName)  \n",
    "    sgd = SGD(decay=0.0001,momentum=0.9)  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(X_Train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(n):\n",
    "    save_folder = 'models/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + dataset + '/' + str(n)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    # serialize model to JSON\n",
    "    #import pickle\n",
    "    model_json = model.to_json()\n",
    "    with open(os.path.join(save_folder, ModelName + \".json\"), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save(os.path.join(save_folder, ModelName + \".h5\"))\n",
    "    #pickle.dump(history.history, open('history/UCMerced_LandUse/AlexNet.p','wb'))\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \" Saved Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = np.loadtxt(base_path + \"/\" + dataset + \"-Test-2048D.txt\")\n",
    "def SaveFeature():\n",
    "    save_folder = 'FeatureMap/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + ModelName + '/' + dataset + '/'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    from keras.models import Model  \n",
    "    for n in DNNlayers:\n",
    "        OutPutLayer = Model(inputs=model.input, outputs=model.get_layer('fc%d' %n).output)\n",
    "        print(\"Saved %d FeatureMap to disk...\" %n)\n",
    "        OutputFeatures=[]\n",
    "        for i in range(0, len(X_Test)):\n",
    "            p = OutPutLayer.predict(X_Test[i : i + 1])\n",
    "            out=np.reshape(p,p.shape[1])\n",
    "            OutputFeatures.append(out)\n",
    "            print(\"\\r当前输出：%d\" %(i + 1), end= \" \")\n",
    "\n",
    "        OutputFeatures = np.array(OutputFeatures, dtype=\"float\") \n",
    "        np.savetxt(os.path.join(save_folder, dataset + '-Test-%dD.txt' %n), OutputFeatures)\n",
    "        print(\"\\n保存完成！\")\n",
    "        print(OutputFeatures.shape)\n",
    "        \n",
    "def SaveOutputFeature():\n",
    "    save_folder = 'FeatureMap/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + ModelName + '/' + dataset + '/'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    from keras.models import Model  \n",
    "    OutPutLayer = Model(inputs=model.input, outputs=model.get_layer('outputFeature').output)\n",
    "    print(\"Saved FeatureMap to disk...\")\n",
    "    OutputFeatures=[]\n",
    "    for i in range(0, len(X_Test)):\n",
    "        p = OutPutLayer.predict(X_Test[i : i + 1])\n",
    "        out=np.reshape(p,p.shape[1])\n",
    "        OutputFeatures.append(out)\n",
    "        print(\"\\r当前输出：%d\" %(i + 1), end= \" \")\n",
    "\n",
    "    OutputFeatures = np.array(OutputFeatures, dtype=\"float\") \n",
    "    np.savetxt(os.path.join(save_folder, dataset + '-Test-%dD.txt' %OutputFeatures.shape[-1]), OutputFeatures)\n",
    "    print(\"\\n保存完成！\")\n",
    "    print(OutputFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0)\n",
    "SaveModel()\n",
    "SaveOutputFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
